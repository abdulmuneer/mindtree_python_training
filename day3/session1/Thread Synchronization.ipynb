{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### avoid conflicts when more than one thread needs to access a single variable or other resource.\n",
    "For example, consider a program that does some kind of processing, and keeps track of how many items it has processed:\n",
    "```python\n",
    "counter = 0\n",
    "\n",
    "def process_item(item):\n",
    "    global counter\n",
    "    ... do something with item ...\n",
    "    counter += 1\n",
    "```\n",
    "\n",
    "#### Atomic Operations \n",
    "\n",
    "The simplest way to synchronize access to shared variables or other resources is to rely on atomic operations in the interpreter. An atomic operation is an operation that is carried out in a single execution step, without any chance that another thread gets control.\n",
    "\n",
    "In general, this approach only works if the shared resource consists of a single instance of a core data type, such as a string variable, a number, or a list or dictionary. Here are some thread-safe operations:\n",
    "\n",
    "    reading or replacing a single instance attribute\n",
    "    reading or replacing a single global variable\n",
    "    fetching an item from a list\n",
    "    modifying a list in place (e.g. adding an item using append)\n",
    "    fetching an item from a dictionary\n",
    "    modifying a dictionary in place (e.g. adding an item, or calling the clear method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locks\n",
    "\n",
    "```python\n",
    "from threading import Lock\n",
    "lock = Lock()\n",
    "\n",
    "lock.acquire()\n",
    "try:\n",
    "    ... access shared resource\n",
    "finally:\n",
    "    lock.release() # release lock, no matter what\n",
    "```\n",
    "\n",
    "#### or..\n",
    "\n",
    "```python\n",
    "with lock:\n",
    "    ... access shared resource\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A possible problem with locks....\n",
    "\n",
    "```python\n",
    "lock = threading.Lock()\n",
    "\n",
    "def get_first_part():\n",
    "    lock.acquire()\n",
    "    try:\n",
    "        ... fetch data for first part from shared object\n",
    "    finally:\n",
    "        lock.release()\n",
    "    return data\n",
    "\n",
    "def get_second_part():\n",
    "    lock.acquire()\n",
    "    try:\n",
    "        ... fetch data for second part from shared object\n",
    "    finally:\n",
    "        lock.release()\n",
    "    return data\n",
    "    \n",
    "\n",
    "def get_both_parts():\n",
    "    first = get_first_part() #call 1\n",
    "    second = get_second_part() # call 2\n",
    "    return first, second\n",
    "    \n",
    "```\n",
    "#### But what if some other thread modifies the resource between call1 and call2 ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we need one more lock to tie both together\n",
    "```python\n",
    "def get_both_parts():\n",
    "    lock.acquire()\n",
    "    try:\n",
    "        first = get_first_part()\n",
    "        second = get_second_part()\n",
    "    finally:\n",
    "        lock.release()\n",
    "    return first, second\n",
    " ```\n",
    " \n",
    " #### Now that is another problem! The individual access functions will get stuck..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Entrant Locks (RLock)\n",
    "The RLock class is a version of simple locking that only blocks if the lock is held by **another** thread.\n",
    "\n",
    "```python\n",
    "lock = threading.Lock()\n",
    "lock.acquire()\n",
    "lock.acquire() # this will block\n",
    "\n",
    "```\n",
    "\n",
    "#### But with RLock\n",
    "\n",
    "```python\n",
    "\n",
    "lock = threading.RLock()\n",
    "lock.acquire()\n",
    "lock.acquire() # this won't block\n",
    "```\n",
    "\n",
    "#### Note that this lock keeps track of the recursion level, so you still need to call release once for each call to acquire.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semaphores\n",
    "\n",
    "** A semaphore has an internal counter rather than a lock flag** \n",
    "\n",
    "** it only blocks if more than a given number of threads have attempted to hold the semaphore. **\n",
    "\n",
    "** Depending on how the semaphore is initialized, this allows multiple threads to access the same code section simultaneously. **\n",
    "\n",
    "\n",
    "```python\n",
    "max_connections = 10\n",
    "\n",
    "semaphore = threading.BoundedSemaphore(max_connections)\n",
    "semaphore = threading.BoundedSemaphore()\n",
    "semaphore.acquire() # decrements the counter\n",
    "... access the shared resource\n",
    "semaphore.release() # increments the counter\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signalling\n",
    "\n",
    "Although the point of using multiple threads is to spin separate operations off to run concurrently, there are times when it is important to be able to synchronize the operations in two or more threads. \n",
    "\n",
    "A simple way to communicate between threads is using **Event** objects. \n",
    "\n",
    "An Event manages an internal flag that callers can either set() or clear(). \n",
    "\n",
    "Other threads can wait() for the flag to be set(), effectively blocking progress until allowed to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import threading\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(%(threadName)-10s) %(message)s',\n",
    "                    )\n",
    "                    \n",
    "def wait_for_event(e):\n",
    "    \"\"\"Wait for the event to be set before doing anything\"\"\"\n",
    "    logging.debug('wait_for_event starting')\n",
    "    event_is_set = e.wait()\n",
    "    logging.debug('event set: %s', event_is_set)\n",
    "\n",
    "def wait_for_event_timeout(e, t):\n",
    "    \"\"\"Wait t seconds and then timeout\"\"\"\n",
    "    while not e.isSet():\n",
    "        logging.debug('wait_for_event_timeout starting')\n",
    "        event_is_set = e.wait(t)\n",
    "        logging.debug('event set: %s', event_is_set)\n",
    "        if event_is_set:\n",
    "            logging.debug('processing event')\n",
    "        else:\n",
    "            logging.debug('doing other work')\n",
    "\n",
    "\n",
    "e = threading.Event()\n",
    "t1 = threading.Thread(name='block', \n",
    "                      target=wait_for_event,\n",
    "                      args=(e,))\n",
    "t1.start()\n",
    "\n",
    "t2 = threading.Thread(name='non-block', \n",
    "                      target=wait_for_event_timeout, \n",
    "                      args=(e, 2))\n",
    "t2.start()\n",
    "\n",
    "logging.debug('Waiting before calling Event.set()')\n",
    "time.sleep(3)\n",
    "e.set()\n",
    "logging.debug('Event is set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
